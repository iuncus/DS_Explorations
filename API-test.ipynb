{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os  \n",
    "import time\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = \"bouguereau\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make request\n",
    "api_url = \"https://collectionapi.metmuseum.org/public/collection/v1\"\n",
    "endpoint = \"/search\"\n",
    "url = api_url+endpoint\n",
    "#Dictionary of parameters â€“ check the documentation for parameters to your liking\n",
    "params = {'q': term, \n",
    "          'hasImages': True,\n",
    "          'departmentID': 11, #in the documentation I found that the ID for European Paintings is 11\n",
    "          # 'dateBegin' : 1800,\n",
    "          # 'dateEnd': 1905\n",
    "          }\n",
    "response = requests.get(url, params = params)\n",
    "print(response.url)\n",
    "print(\"STATUS:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_json = response.json()\n",
    "temp_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "api_url = \"https://collectionapi.metmuseum.org/public/collection/v1/objects/\"\n",
    "\n",
    "for i in temp_json['objectIDs']:\n",
    "    url = api_url + str(i)\n",
    "    response = requests.get(url).json()\n",
    "    results.append(response)\n",
    "\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using pandas, we can use json_normalize to put our data into a dataframe!\n",
    "df = pd.json_normalize(results)\n",
    "\n",
    "df = df[['objectID', 'primaryImage','department','objectName','title','artistDisplayName','objectDate']]\n",
    "\n",
    "# df = df[df['primaryImage'].notna()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge(list1, list2):    \n",
    "    merged_list = [(list1[i], list2[i]) for i in range(0, len(list1))]\n",
    "    return merged_list\n",
    "\n",
    "def download_image(img_list, file_path):\n",
    "    # print(image_list[1])\n",
    "    # img_list[1].decode(\"utf-8\")\n",
    "    filename = '{}.jpg'.format(img_list[0])\n",
    "    fullpath = '{}{}'.format(file_path, filename)\n",
    "    try: \n",
    "        urllib.request.urlretrieve(img_list[1], fullpath) \n",
    "    except URLError:\n",
    "        print(f\"Error downloading: {img_list[0]}\")\n",
    "        errorlist.append(img_list[0])\n",
    "    except HTTPError:\n",
    "        print(f\"Error downloading: {img_list[0]}\")\n",
    "        errorlist.append(img_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this returns a list of tuples of object ID and their image URls\n",
    "image_url = df['primaryImage'].to_list()\n",
    "\n",
    "# image_url = image_url.replace(\"\\\\\", \"/\")\n",
    "image_url = [str(str(i).replace(\"\\\\\", \"/\").replace(\" \", \"\")) for i in image_url]\n",
    "\n",
    "image_id = df['objectID'].to_list()\n",
    "image_list = merge(image_id, image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_url[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = term\n",
    "file_path = os.path.join(\"data/\", directory + \"/\")  \n",
    "os.mkdir(file_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#download images, BE CAREFUL about how many images you have! i'd suggest to stop at 100. simply index image_list like so: image_list[:n]\n",
    "\n",
    "#the errorlist flags what images did not download for whatever reason\n",
    "errorlist= []\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "for url in image_list:\n",
    "    # url.decode('utf-8')\n",
    "    try:\n",
    "         download_image(url, file_path)\n",
    "    except UnicodeEncodeError:\n",
    "        print(\"probably has a - somewhere\")\n",
    "    except ValueError:\n",
    "        print(\"no link for some reason\")\n",
    "    \n",
    "        \n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(f'Finished in {t2-t1} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
